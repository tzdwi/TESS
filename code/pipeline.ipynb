{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.table import Table, vstack\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "from astropy.stats import LombScargle\n",
    "from scipy import stats\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'massive_2min.csv'\n",
    "data_dir = '../data/massive_lcs/'\n",
    "massive = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lc_from_id(ticid, normalize=True, clean=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Step 1: load in the light curve from the TIC number\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    ticid : int\n",
    "        TIC number\n",
    "    \n",
    "    normalize : bool, default True\n",
    "        If True, median divides each Sector's data, creates a column 'NormPDCSAP_FLUX'\n",
    "        \n",
    "    clean : bool, default True\n",
    "        If True, selects only data with QUALITY = 0\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    outlc : `pandas.DataFrame`\n",
    "        Pandas DataFrame containing the lightcurve, with all sector's lightcurves appended\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        \n",
    "        files = glob(data_dir+'*{}*'.format(ticid))\n",
    "        if len(files) == 0:\n",
    "            raise ValueError('TIC number not recognized')\n",
    "        elif len(files) > 2:\n",
    "            raise ValueError('TIC number ambiguous')\n",
    "        else:\n",
    "            lcs = []\n",
    "            for f in files:\n",
    "                lc = Table.read(f, format='fits')\n",
    "                if clean:\n",
    "                    lc = lc[lc['QUALITY'] == 0]\n",
    "                if normalize:\n",
    "                    lc['NormPDCSAP_FLUX'] = lc['PDCSAP_FLUX']/np.nanmedian(lc['PDCSAP_FLUX'])\n",
    "                lcs.append(lc)\n",
    "            outlc = vstack(lcs)\n",
    "            return outlc.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_finder(f,p,n,FAL=0,width=20):\n",
    "    \"\"\"Given frequency/power periodogram, find the first n peaks with power greater than FAL\"\"\"\n",
    "    \n",
    "    assert (len(f) == len(p))&(len(f) > width),\"Length of frequency array and power array much be equal, and >20\"\n",
    "    \n",
    "    peaks = []\n",
    "    strengths = []\n",
    "    \n",
    "    for i in range(width,len(f) - width):\n",
    "        \n",
    "        if np.all(p[i] > p[i -width:i])&np.all(p[i] > p[i + 1:i+width+1])&(p[i]>FAL):\n",
    "            \n",
    "            peaks.append(f[i])\n",
    "            strengths.append(p[i])\n",
    "    \n",
    "    isort = np.argsort(strengths)\n",
    "    peaks = np.array(peaks)[isort]\n",
    "    strengths = np.array(strengths)[isort]\n",
    "    return peaks[::-1][:n],strengths[::-1][:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_periodic_components(ticid, phaseplot = True, dynamicplot = True, pmin = 0.1, pmax = 28.0, **kwargs):\n",
    "    \n",
    "    \"\"\"\n",
    "    Step 2: Identify and separate periodic features.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ticid : int\n",
    "        TIC number\n",
    "        \n",
    "    phaseplot : bool, default True\n",
    "        If True, for each significant period above white noise, subtracts the other periods, then phase folds the data and plot\n",
    "        \n",
    "    dynamicplot : bool, default True\n",
    "        If True, for each significant period above white noise, subtracts the other periods, plots phase vs. cycle number\n",
    "        \n",
    "    pmin : float, default 0.1\n",
    "        Minimum period to search for in the data\n",
    "    \n",
    "    pmax : float, default 28.0\n",
    "        Maximum period to search for in the data\n",
    "        \n",
    "    **kwargs\n",
    "        Passed to get_lc_from_id\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    Ps : array-like\n",
    "        Array of significant periods above white noise \n",
    "        \n",
    "    ts : array-like\n",
    "        Times of lightcurve\n",
    "        \n",
    "    flux : array-like\n",
    "        Flux\n",
    "    \n",
    "    whitened_flux : array-like\n",
    "        Flux after getting rid of the periodic components\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #Book keeping\n",
    "    name = np.unique(massive['CommonName'][massive['ticid']==ticid])[0]\n",
    "    spt = np.unique(massive['SpT'][massive['ticid']==ticid])[0]\n",
    "    \n",
    "\n",
    "    #Assemble the lightcurve, plus the smoothed light curve, get rid of NaNs\n",
    "    lc = get_lc_from_id(ticid, **kwargs)\n",
    "    slc = lc.rolling(128, center=True).median()\n",
    "    \n",
    "    rtime = lc['TIME'].values\n",
    "    if 'NormPDCSAP_FLUX' in lc.columns:\n",
    "        rflux = lc['NormPDCSAP_FLUX'].values\n",
    "    else:\n",
    "        rflux = lc['PDCSAP_FLUX'].values\n",
    "    \n",
    "    time = rtime[~np.isnan(rflux)]\n",
    "    flux = rflux[~np.isnan(rflux)]\n",
    "    \n",
    "    srtime = slc['TIME'].values\n",
    "    if 'NormPDCSAP_FLUX' in lc.columns:\n",
    "        srflux = slc['NormPDCSAP_FLUX'].values\n",
    "    else:\n",
    "        srflux = slc['PDCSAP_FLUX'].values\n",
    "    \n",
    "    stime = srtime[~np.isnan(srflux)]\n",
    "    sflux = srflux[~np.isnan(srflux)]\n",
    "    \n",
    "    LS_obj = LombScargle(time, flux)\n",
    "    \n",
    "    f, p = LS_obj.autopower(minimum_frequency=1.0/pmax,\n",
    "                            maximum_frequency=1.0/pmin)\n",
    "    \n",
    "    #Assume the null hypothesis is white noise, find peaks with FAP < 0.001\n",
    "    FAL = LS_obj.false_alarm_level(0.01)\n",
    "    \n",
    "    fs, ps = peak_finder(f, p, 10, FAL=FAL, width=10)\n",
    "    \n",
    "    plt.plot(1.0/f,p)\n",
    "    plt.scatter(1.0/fs,ps)\n",
    "    plt.xlabel('Period [d]')\n",
    "    plt.ylabel('Power')\n",
    "    plt.title('{0}: {1}'.format(name,spt))\n",
    "    plt.savefig('{0}_periodogram.png'.format(name.replace('*','').replace(' ','')))\n",
    "    plt.close('all')\n",
    "    \n",
    "    #Copy the flux array to return later after we subtract off all the signals\n",
    "    whitened_flux = flux.copy()\n",
    "    for i,freq in enumerate(fs):\n",
    "        \n",
    "        #make a copy of the flux - more significant peaks\n",
    "        temp_flux = whitened_flux.copy()\n",
    "        \n",
    "        #subtract off the model for this frequency from the temp flux array and also the \n",
    "        #whitened flux\n",
    "        sub_ls = LombScargle(time,temp_flux)\n",
    "        temp_model = sub_ls.model(time, freq)\n",
    "        temp_flux -= temp_model\n",
    "        whitened_flux -= temp_model\n",
    "\n",
    "        #iterate over less significant peaks\n",
    "        other_freqs = fs[i+1:]\n",
    "\n",
    "        for of in other_freqs:\n",
    "            #subtract off the model for these frequencies\n",
    "            temp_ls = LombScargle(time, temp_flux)\n",
    "            mod = temp_ls.model(time, of)\n",
    "            temp_flux -= mod\n",
    "        \n",
    "        #add the model back in\n",
    "        temp_flux += temp_model\n",
    "        \n",
    "        #Only plot the biggest 3 components\n",
    "        if i < 3:\n",
    "            phase = (time*freq) % 1\n",
    "            if phaseplot:\n",
    "                lc_df = pd.DataFrame(data={'Phase':phase,'Flux':temp_flux}).sort_values('Phase')\n",
    "                lc_df_smooth = lc_df.rolling(128, center=True).median()\n",
    "                plt.scatter(lc_df['Phase'],lc_df['Flux'],s=1)\n",
    "                plt.plot(lc_df_smooth['Phase'],lc_df_smooth['Flux'],c='C1')\n",
    "                plt.xlabel('Phase')\n",
    "                plt.ylabel('Flux - Other Periods')\n",
    "                plt.xlim(0,1)\n",
    "                plt.ylim(0.9999*np.min(temp_flux),1.0001*np.max(temp_flux))\n",
    "                plt.title('{0}: {1}. P={2}'.format(name,spt,1.0/freq))\n",
    "                plt.savefig('{0}_phase_P{1}.png'.format(name.replace('*','').replace(' ',''),i))\n",
    "                plt.close('all')\n",
    "                \n",
    "            if dynamicplot:\n",
    "                cycle = np.floor((time-np.min(time))*freq)\n",
    "                ybins = len(np.unique(cycle))\n",
    "                xbins = 100\n",
    "                H, xedges, yedges, binnumber = stats.binned_statistic_2d(phase, cycle, temp_flux, statistic='median', bins=(xbins,ybins))  \n",
    "                H = np.ma.masked_where(H==0, H) #masking where there was no data\n",
    "                XX, YY = np.meshgrid(xedges, (ybins/(ybins-1))*yedges+0.5)\n",
    "                colobj = plt.pcolormesh(XX,YY,H.T)\n",
    "                plt.xlabel('Phase')\n",
    "                plt.ylabel('Cycle')\n",
    "                plt.colorbar(colobj, ax=plt.gca(), label='Median Flux Per Bin')\n",
    "                plt.title('{0}: {1}. P={2}'.format(name,spt,1.0/freq))\n",
    "                plt.savefig('{0}_dynamic_P{1}.png'.format(name.replace('*','').replace(' ',''),i))\n",
    "                plt.close('all')\n",
    "                \n",
    "    return 1.0/fs, time, flux, whitened_flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29281992\n",
      "29984014\n",
      "31530164\n",
      "55295028\n",
      "55401985\n",
      "126658353\n",
      "150392584\n",
      "160192386\n",
      "167304735\n",
      "167720039\n",
      "179305185\n",
      "220424200\n",
      "232083010\n",
      "255686390\n",
      "269794986\n",
      "278611926\n",
      "279957111\n",
      "281741629\n",
      "307160124\n",
      "370227780\n",
      "389076668\n",
      "389437365\n",
      "410447919\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    for tic in np.unique(massive['ticid']):\n",
    "        print(tic)\n",
    "        extract_periodic_components(tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
